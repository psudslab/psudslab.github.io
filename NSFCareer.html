<!DOCTYPE HTML>
<html>
	<head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>PSU Data Science Lab</title>
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="description" content="PSU Data Science Lab's Homepage" />
	<meta name="keywords" content="Fenglong Ma, data science, data mining, Penn State, IST" />
	<meta name="author" content="Fenglong Ma" />

  <!-- Facebook and Twitter integration -->
	<meta property="og:title" content=""/>
	<meta property="og:image" content=""/>
	<meta property="og:url" content=""/>
	<meta property="og:site_name" content=""/>
	<meta property="og:description" content=""/>
	<meta name="twitter:title" content="" />
	<meta name="twitter:image" content="" />
	<meta name="twitter:url" content="" />
	<meta name="twitter:card" content="" />

	<!-- Place favicon.ico and apple-touch-icon.png in the root directory -->
	<link rel="shortcut icon" href="favicon.ico">

	<link href="https://fonts.googleapis.com/css?family=Quicksand:300,400,500,700" rel="stylesheet">
	<link href="https://fonts.googleapis.com/css?family=Playfair+Display:400,400i,700" rel="stylesheet">
	
	<!-- Animate.css -->
	<link rel="stylesheet" href="css/animate.css">
	<!-- Icomoon Icon Fonts-->
	<link rel="stylesheet" href="css/icomoon.css">
	<!-- Bootstrap  -->
	<link rel="stylesheet" href="css/bootstrap.css">
	<!-- Flexslider  -->
	<link rel="stylesheet" href="css/flexslider.css">
	<!-- Flaticons  -->
	<link rel="stylesheet" href="fonts/flaticon/font/flaticon.css">
	<!-- Owl Carousel -->
	<link rel="stylesheet" href="css/owl.carousel.min.css">
	<link rel="stylesheet" href="css/owl.theme.default.min.css">
	<!-- Theme style  -->
	<link rel="stylesheet" href="css/style.css">

	<!-- Modernizr JS -->
	<script src="js/modernizr-2.6.2.min.js"></script>
	<!-- FOR IE9 below -->
	<!--[if lt IE 9]>
	<script src="js/respond.min.js"></script>
	<![endif]-->

	</head>
	<body>
	<div id="colorlib-page">
		<div class="container-wrap">
		<a href="#" class="js-colorlib-nav-toggle colorlib-nav-toggle" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar"><i></i></a>
		<aside id="colorlib-aside" role="complementary" class="border js-fullheight">
			<div class="text-center">
				<div class="author-img" style="background-image: url(images/ds_photo.jpg);"></div>
				<h1 id="colorlib-logo"><a href="index.html">PSU Data Science Lab</a></h1>
				<span class="position">
					<a href="https://www.psu.edu"><font color="grey">Pennsylvania State University</font></a>
				</span>
			</div>

			<nav id="colorlib-main-menu">
				<div>
					<ul>
						<li class="active"><a href="index.html">Home</a></li>
						<li><a href="Research.html" >Research</a></li>
						<li><a href="Publications.html">Publications</a></li>
						<li><a href="People.html">People</a></li>
						<li><a href="Contact.html">Contact</a></li>
					</ul>
				</div>
			</nav>
			<br>

			<div class="text-center">
				<p><font color="red"><b>Acknowledgement</b></font></p>

				<div class="field field-name-field-image field-type-image field-label-hidden">
					<div class="field-items">
					  <div class="field-item even">
						<center>
						  <img src="images/NSF.svg.png" width=140 height=140  alt=""/>
						</center>
					  </div>
					</div>
				  </div>
				  <br>

				  <div class="field field-name-field-image field-type-image field-label-hidden">
					<div class="field-items">
					  <div class="field-item even">
						<center>
						  <img src="images/nih-nia.png" width=120 height=120  alt=""/>
						</center>
					  </div>
					</div>
				  </div>
				  <br>

				  <div class="field field-name-field-image field-type-image field-label-hidden">
					<div class="field-items">
					  <div class="field-item even">
						<center>
						  <img src="images/Sony.png" width=120 height=60  alt=""/>
						</center>
					  </div>
					</div>
				  </div>

				<div class="field field-name-field-image field-type-image field-label-hidden">
					<div class="field-items">
					  <div class="field-item even">
						<center>
						  <img src="images/Penn-State-University-Emblem.png" width=240 height=120  alt=""/>
						</center>
					  </div>
					</div>
				  </div>
				
			</div>
			

			<div class="colorlib-footer">
				<p><small>&copy; <!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
					Copyright &copy;<script>document.write(new Date().getFullYear());</script> All rights reserved | This template is made with 
					<i class="icon-heart" aria-hidden="true"></i> by <a href="https://colorlib.com" target="_blank">Colorlib</a>
					<!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. --> </span> 
				<span>Last Update: Mar 15, 2022</span></small></p>
			</div>
			<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=tt&d=uk7inqkcxD7zV_n2SjGvBUPL002nRyMsNt895CillEg&co=8ac4ed'></script>
		</aside>

		<div id="colorlib-main">
		
			<section id="colorlib-home" data-section="home">			  	
			  	<div class="colorlib-narrow-content">
					<div class="row">
						<div class="col-md-12">
							<div class="row row-bottom-padded-sm animate-box">
								<div class="col-md-12">
								<p><br></p>
									<div class="about-desc">
										<span class="heading-meta">National Science Foundation (NSF)</span>
										<h2 class="colorlib-heading">CAREER: Automated Multimodal Learning for Healthcare</h2>

										<p style="text-align:justify; text-justify:inter-ideograph;"> 
											Multimodal learning is one of the central tasks of artificial intelligence (AI), which aims to effectively 
											fuse and model multimodal data to gain a better understanding of the world around us. Many multimodal fusion 
											strategies have been proposed, ranging from manually designed policies to advanced automated machine learning 
											(AutoML)-based approaches. Although AutoML-based solutions outperform handcrafted ones, they are still far 
											from optimal due to their lack of generalizability in model design and failure to account for the unique 
											characteristics of multimodal data. This project takes the multimodal healthcare predictive modeling task 
											as a representative example, aiming to discover and identify the optimal way to fuse multimodal data via a 
											new learning paradigm, i.e., automated multimodal learning, with minimal human interventions. 
											The success of this project will yield new fundamental knowledge in various fields, including automated 
											machine learning, multimodal deep learning, and healthcare predictive modeling. The new automated multimodal 
											learning paradigm will revolutionize multimodal data mining by automatically searching for new and complex 
											yet optimal fusion strategies from the data, potentially motivating researchers and domain experts to 
											understand the multimodal data better. In addition, recognizing unique research challenges posed by 
											the unique nature of multimodal data in the healthcare domain and providing customized solutions will 
											advance the research of healthcare predictive modeling significantly.<br>
											
											To meet these goals, the investigator proposes to equip automated multimodal learning with the ability 
											to model the unique challenges of multimodal health data, including data size variety, noise, and 
											missing modalities. The investigator also proposes to validate the proposed research for different 
											multimodal fusion tasks in healthcare informatics and beyond and gather feedback from experts to 
											refine the proposed research. The results of this project will provide a needed paradigm shift 
											toward automated multimodal data fusion, impacting a broad range of research fields, including 
											machine learning, data mining, and healthcare informatics. The proposed research will also make 
											an enduring contribution to multimodal predictive modeling in clinical practice and other domains. 
											The generated data, source codes, and software tools will be made available to researchers worldwide. 
											The open platform will expedite research, enhance global collaborations in this field, and provide 
											longstanding value for academia, healthcare organizations, and health industries. The proposed education 
											plan will help to ensure that graduates are well equipped to design and evaluate machine learning 
											solutions and cultivate K-12 students' interest in computer science and informatics. It will also lead 
											to a more diverse population of undergraduate research assistants and enhance collaboration and networking 
											among graduate students.
										</p>

										<p style="font-weight:bold">
											<font color="blue">Students</font>
										</p>
                    									<li>Aofei Chang (Penn State)</li>
                    									<li>Xiaochen Wang (Penn State)</li>
											<li>Yuan Zhong (Penn State)</li>
										</br>

										<p style="font-weight:bold">
											<font color="blue">Publications</font>
										</p>
										<li>
							<a><font color="blue">Asymmetrical Reciprocity-based Federated Learning for Resolving Disparities in Medical Diagnosis</font></a><br>
							 <u>Jiaqi Wang</u>*, <u>Ziyi Yin</u>*, Quanzeng You, Lingjuan Lyu, and <font color="black">Fenglong Ma</font><br>
							<em>Proceedings of the 31st SIGKDD Conference on Knowledge Discovery and Data Mining</em> 
							(<font color="red">KDD 2025</font>), August 3 - 7, 2025, Toronto, ON, Canada. (* equal contribution, August cycle research track acceptance rate: 19%)
						</li>

<li>
							<a><font color="blue">Multimodal Artificial Intelligence in Healthcare</font></a><br>
							 <u>Jiaqi Wang</u>, <u>Xiaochen Wang</u>, <u>Yuan Zhong</u>, <u>Ziyi Yin</u>, <u>Aofei Chang</u>, Cao Xiao, and <font color="black">Fenglong Ma</font><br>
							<em>Conference Tutorial at the Thirty-Ninth AAAI Conference on Artificial Intelligence</em> 
							(<font color="red">AAAI 2025</font>), February 25 - March 4, 2025, Philadelphia, Pennsylvania, USA.
						</li>

<li>
							<a><font color="blue">FedMeKI: A Benchmark for Scaling Medical Foundation Models via Federated Knowledge Injection</font></a><br>
							 <u>Jiaqi Wang</u>*, <u>Xiaochen Wang</u>*, Lingjuan Lyu, Jinghui Chen and <font color="black">Fenglong Ma</font><br>
							<em>Proceedings of the Thirty-eighth Annual Conference on Neural Information Processing Systems</em> 
							(<font color="red">NeurPIS 2024</font>), December 9-15, 2024, Vancouver, Canada. (<font color="red">Spotlight</font>, * equal contribution, datasets and benchmarks track acceptance rate: 25.3%)
						</li>

<li>
							<a><font color="blue">Asymmetric Mutual Learning for Decentralized Federated Medical Imaging</font></a><br>
							 <u>Jiaqi Wang</u>, Houping Xiao and <font color="black">Fenglong Ma</font><br>
							<em>Proceedings of the 15th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics</em> 
							(<font color="red">ACM-BCB 2024</font>), November 22-25, 2024, Shenzhen, China. (Oral acceptance rate: 17.6%)
						</li>
						<li>
							<a><font color="blue">FEDKIM: Adaptive Federated Knowledge Injection into Medical Foundation Models</font></a><br>
							 <u>Xiaochen Wang</u>*, <u>Jiaqi Wang</u>*, Houping Xiao, Jinghui Chen and <font color="black">Fenglong Ma</font><br>
							<em>Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing</em> 
							(<font color="red">EMNLP 2024 Main</font>), November 12 –16, Miami, Florida. (* equal contribution)
						</li>
						<li>
							<a><font color="blue">BIPEFT: Budget-Guided Iterative Search for Parameter Efficient Fine-Tuning of Large Pretrained Language Models</font></a><br>
							 <u>Aofei Chang</u>, <u>Jiaqi Wang</u>, Han Liu, Parminder Bhatia, Cao Xiao, Ting Wang and <font color="black">Fenglong Ma</font><br>
							<em>Findings of the 2024 Conference on Empirical Methods in Natural Language Processing</em> 
							(<font color="red">EMNLP 2024 Findings</font>), November 12 –16, Miami, Florida.
						</li>

<li>
							<a><font color="blue">Synthesizing Multimodal Electronic Health Records via Predictive Diffusion Models</font></a><br>
							 <u>Yuan Zhong</u>, <u>Xiaochen Wang</u>, <u>Jiaqi Wang</u>, <u>Xiaokun Zhang</u>, Yaqing Wang, Mengdi Huai, Cao Xiao and <font color="black">Fenglong Ma</font><br>
							<em>Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</em> 
							(<font color="red">KDD 2024</font>), Aug. 25-29, 2024, Barcelona, Spain.
						</li>

<li>
							<a><font color="blue">Unity in Diversity: Collaborative Pre-training Across Multimodal Medical Sources</font></a><br>
							 <u>Xiaochen Wang</u>, <u>Junyu Luo</u>, <u>Jiaqi Wang</u>, <u>Yuan Zhong</u>, <u>Xiaokun Zhang</u>, Yaqing Wang, Parminder Bhatia, Cao Xiao and <font color="black">Fenglong Ma</font><br>
							<em>Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics</em> 
							(<font color="red">ACL 2024</font>), August 11-16, 2024, Bangkok, Thailand.
						</li>

<li>
							<a><font color="blue">Recent Advances in Predictive Modeling with Electronic Health Records</font></a>[<a href="https://arxiv.org/pdf/2402.01077">Paper</a>]</a>[<a href="./files/ijcai24-survey.pdf">Slides</a>]<br>
							 <u>Jiaqi Wang</u>, <u>Junyu Luo</u>, <u>Muchao Ye</u>, <u>Xiaochen Wang</u>, <u>Yuan Zhong</u>,
							<u>Aofei Chang</u>, <u>Guanjie Huang</u>, <u>Ziyi Yin</u>, Cao Xiao, Jimeng Sun and <font color="black">Fenglong Ma</font><br>
							<em>Proceedings of the 33rd International Joint Conference on Artificial Intelligence</em> 
							(<font color="red">IJCAI 2024</font>), Aug. 3-9, 2024, Jeju, South Korea. (Survey Track, acceptance rate: 20.7%)
						</li>
										<li>
											<a><font color="blue">Automated Fusion of Multimodal Electronic Health Records for Better Medical Predictions</font></a><br>
											<u>Suhan Cui</u>, <u>Jiaqi Wang</u>, <u>Yuan Zhong</u>, Han Liu, Ting Wang and <font color="black">Fenglong Ma</font><br>
											<em>Proceedings of the 24th SIAM International Conference on Data Mining</em> 
											(<font color="red">SDM 2024</font>), accepted. (acceptance rate: 29.2%)
										</li>

										<li>
											<a><font color="blue">MedDiffusion: Boosting Health Risk Prediction via Diffusion-based Data Augmentation</font></a><br>
											<u>Yuan Zhong</u>, <u>Suhan Cui</u>, <u>Jiaqi Wang</u>, <u>Ziyi Yin</u>, Yaqing Wang, Houping Xiao, Mengdi Huai, Ting Wang and <font color="black">Fenglong Ma</font><br>
											<em>Proceedings of the 24th SIAM International Conference on Data Mining</em> 
											(<font color="red">SDM 2024</font>), accepted. (acceptance rate: 29.2%)
										</li>
										
										<li>
											<a><font color="blue">Hierarchical Pretraining on Multimodal Electronic Health Records</font></a><br>
											<u>Xiaochen Wang</u>, <u>Junyu Luo</u>, <u>Jiaqi Wang</u>, <u>Ziyi Yin</u>, <u>Suhan Cui</u>, <u>Yuan Zhong</u>, Yaqing Wang and <font color="black">Fenglong Ma</font><br>
											<em>Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em> 
											(<font color="red">EMNLP 2023</font>), December 6-10, 2023, Singapore, accepted.
										</li>
										<li>
											<a><font color="blue">ClinicalRisk: A New Therapy-related Clinical Trial Dataset for Predicting Risk Levels and Risk Factors</font></a><br>
											<u>Junyu Luo</u>, Zhi Qiao, Lucas Glass, Cao Xiao and <font color="black">Fenglong Ma</font><br>
											<em>Proceedings of the 32nd ACM International Conference on Information and Knowledge Management</em> 
											(<font color="red">CIKM 2023</font>), Oct. 21-25, 2023, Birmingham, UK, accepted.  
										</li>
										<li>
											<a><font color="blue">pADR: Towards Personalized Adverse Drug Reaction Prediction</font></a><br>
											<u>Junyu Luo</u>, Cheng Qian, <u>Xiaochen Wang</u>, Lucas Glass and <font color="black">Fenglong Ma</font><br>
											<em>Proceedings of the 32nd ACM International Conference on Information and Knowledge Management</em> 
											(<font color="red">CIKM 2023</font>), Oct. 21-25, 2023, Birmingham, UK, accepted. 
										</li>
									</br>

										<p style="font-weight:bold">
											<font color="blue">Dissemination</font>
										</p>
                    									<li>Aofei Chang (Penn State)</li>
                    									<li>Xiaochen Wang (Penn State)</li>
											<li>Yuan Zhong (Penn State)</li>
										</br>
										
										<p style="font-weight:bold">
											<font color="blue">Softwares</font>
										</p>
										<li>
											<a href="https://github.com/SH-Src/AUTOMF"><font color="blue">AutoFM (SDM 2024)</font></a>
										</li>
										<li>
											<a href="https://shorturl.at/aerT0"><font color="blue">MedDiffusion (SDM 2024)</font></a>
										</li>
										<li>
											<a href="https://github.com/XiaochenWang-PSU/MedHMP"><font color="blue">MedNMP (EMNLP 2023)</font></a>

										</li>


									</div>
								</div>
								
						</div>
					</div>
				</div>
			</section>
			
			
		</div><!-- end:colorlib-main -->
	</div><!-- end:container-wrap -->
	</div><!-- end:colorlib-page -->

	<!-- jQuery -->
	<script src="js/jquery.min.js"></script>
	<!-- jQuery Easing -->
	<script src="js/jquery.easing.1.3.js"></script>
	<!-- Bootstrap -->
	<script src="js/bootstrap.min.js"></script>
	<!-- Waypoints -->
	<script src="js/jquery.waypoints.min.js"></script>
	<!-- Flexslider -->
	<script src="js/jquery.flexslider-min.js"></script>
	<!-- Owl carousel -->
	<script src="js/owl.carousel.min.js"></script>
	<!-- Counters -->
	<script src="js/jquery.countTo.js"></script>
	
	
	<!-- MAIN JS -->
	<script src="js/main.js"></script>

	</body>
</html>

